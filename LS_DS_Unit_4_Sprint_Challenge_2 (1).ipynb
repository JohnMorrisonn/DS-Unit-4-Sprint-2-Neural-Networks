{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Chocolate Gummy Bears](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron\n",
    "4. [Keras MMP](#Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Define the following terms:\n",
    "\n",
    "- **Neuron:** An individual node that takes in an input and gives an activation output\n",
    "- **Input Layer:** The first layer of nodes that takes the inputs of the model\n",
    "- **Hidden Layer:** Layers inbetween input and output nodes that are black box models\n",
    "- **Output Layer:** Last layer to have the final output value/predicted values\n",
    "- **Activation:** Commonly relu or sigmoid, used to convert the input signal to an output after weights/biases\n",
    "- **Backpropagation:** Feeds information back to the previous nodes based on the predicted output errors in order to learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chocolate Gummy Bears <a id=\"Q2\"></a>\n",
    "\n",
    "Right now, you're probably thinking, \"yuck, who the hell would eat that?\". Great question. Your candy company wants to know too. And you thought I was kidding about the [Chocolate Gummy Bears](https://nuts.com/chocolatessweets/gummies/gummy-bears/milk-gummy-bears.html?utm_source=google&utm_medium=cpc&adpos=1o1&gclid=Cj0KCQjwrfvsBRD7ARIsAKuDvMOZrysDku3jGuWaDqf9TrV3x5JLXt1eqnVhN0KM6fMcbA1nod3h8AwaAvWwEALw_wcB). \n",
    "\n",
    "Let's assume that a candy company has gone out and collected information on the types of Halloween candy kids ate. Our candy company wants to predict the eating behavior of witches, warlocks, and ghosts -- aka costumed kids. They shared a sample dataset with us. Each row represents a piece of candy that a costumed child was presented with during \"trick\" or \"treat\". We know if the candy was `chocolate` (or not chocolate) or `gummy` (or not gummy). Your goal is to predict if the costumed kid `ate` the piece of candy. \n",
    "\n",
    "If both chocolate and gummy equal one, you've got a chocolate gummy bear on your hands!?!?!\n",
    "![Chocolate Gummy Bear](https://ed910ae2d60f0d25bcb8-80550f96b5feb12604f4f720bfefb46d.ssl.cf1.rackcdn.com/3fb630c04435b7b5-2leZuM7_-zoom.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "candy = pd.read_csv('chocolate_gummy_bears.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>gummy</th>\n",
       "      <th>ate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chocolate  gummy  ate\n",
       "0          0      1    1\n",
       "1          1      0    1\n",
       "2          0      1    1\n",
       "3          0      0    0\n",
       "4          1      1    0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(candy.shape)\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "To make predictions on the `candy` dataframe. Build and train a Perceptron using numpy. Your target column is `ate` and your features: `chocolate` and `gummy`. Do not do any feature engineering. :P\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why you could not achieve a higher accuracy with a *simple perceptron*. It's possible to achieve ~95% accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Start your candy perceptron here\n",
    "\n",
    "X = candy[['chocolate', 'gummy']].values\n",
    "y = candy['ate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.493"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, no_of_x, niter=1000, learning_rate=0.01):\n",
    "        self.niter = niter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.zeros(no_of_x + 1)\n",
    "        self.errors_ = []\n",
    "    \n",
    "    def transform_df(self, df, target):\n",
    "        X = df.drop(columns=target).to_numpy()\n",
    "        y = df[target].to_numpy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def net_input(self, X_test):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X_test, self.weights[1:]) + self.weights[0]\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X_test) >= 0.0, 1, -1)\n",
    "    \n",
    "    def Errors(self):\n",
    "        return self.errors_\n",
    "\n",
    "    def train(self, X_train, y_train):        \n",
    "        for _ in range(self.niter):\n",
    "            for row, target in zip(X_train, y_train):\n",
    "                prediction = self.predict(row)\n",
    "                delta_w = self.learning_rate * (target - prediction)\n",
    "                self.weights[1:] += delta_w * row\n",
    "                self.weights[0] += delta_w\n",
    "                \n",
    "    def rmse(self, X_test, y_test):\n",
    "        return np.sqrt(np.mean((self.predict(X_test) - y_test) ** 2))\n",
    "    \n",
    "    def acc(self, y_true, y_pred):\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "\n",
    "    \n",
    "pn = Perceptron(2)\n",
    "X_train, X_test, y_train, y_test = pn.transform_df(candy, 'ate')\n",
    "pn.train(X_train, y_train)\n",
    "y_pred = pn.predict(X_test)\n",
    "pn.acc(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With a simple perceptron, you have no hidden layers or backprop to help the model identify different aspects of the dataset and learn from its mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron <a id=\"Q3\"></a>\n",
    "\n",
    "Using the sample candy dataset, implement a Neural Network Multilayer Perceptron class that uses backpropagation to update the network's weights. Your Multilayer Perceptron should be implemented in Numpy. \n",
    "Your network must have one hidden layer.\n",
    "\n",
    "Once you've trained your model, report your accuracy. Explain why your MLP's performance is considerably better than your simple perceptron's on the candy dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------EPOCH 2000---------+\n",
      "Error [[-0.02743428]\n",
      " [-0.02743428]\n",
      " [ 0.04360077]\n",
      " ...\n",
      " [-0.02743428]\n",
      " [-0.02743428]\n",
      " [ 0.04360077]]\n",
      "Input: \n",
      " [[1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.95636407]\n",
      " [0.06413145]\n",
      " [0.94726679]\n",
      " ...\n",
      " [0.94726679]\n",
      " [0.02766046]\n",
      " [0.06413145]]\n",
      "Loss: \n",
      " 0.0432489973238964\n",
      "+---------EPOCH 4000---------+\n",
      "Error [[-0.0560534 ]\n",
      " [-0.0560534 ]\n",
      " [ 0.05316808]\n",
      " ...\n",
      " [-0.0560534 ]\n",
      " [-0.0560534 ]\n",
      " [ 0.05316808]]\n",
      "Input: \n",
      " [[1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.94683193]\n",
      " [0.06131042]\n",
      " [0.94458348]\n",
      " ...\n",
      " [0.94458348]\n",
      " [0.05605398]\n",
      " [0.06131042]]\n",
      "Loss: \n",
      " 0.04313152677004808\n",
      "+---------EPOCH 6000---------+\n",
      "Error [[-0.05671284]\n",
      " [-0.05671284]\n",
      " [ 0.05315465]\n",
      " ...\n",
      " [-0.05671284]\n",
      " [-0.05671284]\n",
      " [ 0.05315465]]\n",
      "Input: \n",
      " [[1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.94684536]\n",
      " [0.06067694]\n",
      " [0.94461688]\n",
      " ...\n",
      " [0.94461688]\n",
      " [0.05671303]\n",
      " [0.06067694]]\n",
      "Loss: \n",
      " 0.043127125425771205\n",
      "+---------EPOCH 8000---------+\n",
      "Error [[-0.05699173]\n",
      " [-0.05699173]\n",
      " [ 0.05314873]\n",
      " ...\n",
      " [-0.05699173]\n",
      " [-0.05699173]\n",
      " [ 0.05314873]]\n",
      "Input: \n",
      " [[1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " ...\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]]\n",
      "Actual Output: \n",
      " [[1]\n",
      " [0]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Predicted Output: \n",
      " [[0.94685128]\n",
      " [0.06040574]\n",
      " [0.94462698]\n",
      " ...\n",
      " [0.94462698]\n",
      " [0.05699183]\n",
      " [0.06040574]]\n",
      "Loss: \n",
      " 0.043125382687221714\n",
      "[[ 0.05314872]\n",
      " [-0.06040564]\n",
      " [ 0.05537301]\n",
      " ...\n",
      " [ 0.05537301]\n",
      " [-0.05699193]\n",
      " [-0.06040564]]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size=2, hidden_size=8, output_size=1, lr=0.01):\n",
    "        # Set up Architecture of Neural Network\n",
    "        self.lr = lr\n",
    "\n",
    "        # Initial Weights\n",
    "        self.weights1 = np.random.rand(input_size, hidden_size) * 0.1\n",
    "       \n",
    "        self.weights2 = np.random.rand(hidden_size, output_size) * 0.1\n",
    "    \n",
    "        self.Bh = np.zeros(hidden_size)\n",
    "        \n",
    "        self.Bo = np.zeros(output_size)\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1+np.exp(-s))\n",
    "    \n",
    "    def relu(self, s):\n",
    "        return np.maximum(0, s)\n",
    "    \n",
    "    def leaky_relu(self, s):\n",
    "        return np.maximum(0.1 * s, s)\n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        aka \"predict\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Weighted sum of inputs => hidden layer\n",
    "        self.hidden_sum = np.dot(X, self.weights1) + self.Bh\n",
    "\n",
    "        \n",
    "        # Activations of weighted sum\n",
    "        self.activated_hidden = self.sigmoid(self.hidden_sum)\n",
    "        \n",
    "        # Weight sum between hidden and output\n",
    "        self.output_sum = np.dot(self.activated_hidden, self.weights2) + self.Bo\n",
    "        \n",
    "        # Final activation of output\n",
    "        self.activated_output = self.sigmoid(self.output_sum)\n",
    "        \n",
    "        return self.activated_output\n",
    "        \n",
    "    def backward(self, X,y,o):\n",
    "        \"\"\"\n",
    "        Backward propagate through the network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Error in Output\n",
    "        self.o_error = y - o\n",
    "        \n",
    "        # Apply Derivative of Sigmoid to error\n",
    "        # How far off are we in relation to the Sigmoid f(x) of the output\n",
    "        # ^- aka hidden => output\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        \n",
    "        # z2 error\n",
    "        self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        # How much of that \"far off\" can explained by the input => hidden\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.activated_hidden)\n",
    "        \n",
    "        # Adjustment to first set of weights (input => hidden)\n",
    "        self.weights1 += X.T.dot(self.z2_delta) * self.lr\n",
    "        # Adjustment to second set of weights (hidden => output)\n",
    "        self.weights2 += self.activated_hidden.T.dot(self.o_delta) * self.lr\n",
    "        # Adjustments to hidden bias\n",
    "        self.Bh += np.sum(self.z2_delta) * self.lr\n",
    "        #Adjustments to output bias\n",
    "        self.Bo += np.sum(self.o_delta) * self.lr\n",
    "\n",
    "    def train(self, X, y):\n",
    "        o = self.feed_forward(X)\n",
    "        self.backward(X,y,o)\n",
    "    \n",
    "    def acc(self, y_true):\n",
    "        y_pred = self.feed_forward(X)\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "        \n",
    "\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "for i in range(8000):\n",
    "    if ((i+1) % 2000 == 0):\n",
    "        print('+' + '---' * 3 + f'EPOCH {i+1}' + '---' * 3 + '+')\n",
    "        print('Error', nn.o_error)\n",
    "        print('Input: \\n', X_test)\n",
    "        print('Actual Output: \\n', y_test)\n",
    "        print('Predicted Output: \\n', str(nn.feed_forward(X_test)))\n",
    "        print('Loss: \\n', str(np.mean(np.square(y_test - nn.feed_forward(X_test)))))\n",
    "    nn.train(X_train, y_train)\n",
    "    \n",
    "print(y_test - nn.feed_forward(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nn.feed_forward(X_test)\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "y_pred1 = np.array(rounded, dtype='int64')\n",
    "accuracy_score(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I should be getting higher results since the network is able to teach itself from its mistakes by calculating the error and increasing or decreasing the bias accordingly\n",
    "#### After fine tuning and removing an error from stratifying during train test split, my loss drastically reduced as it was able to iterate over the error and adjust the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Don't try candy gummy bears. They're disgusting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "Implement a Multilayer Perceptron architecture of your choosing using the Keras library. Train your model and report its baseline accuracy. Then hyperparameter tune at least two parameters and report your model's accuracy.\n",
    "Use the Heart Disease Dataset (binary classification)\n",
    "Use an appropriate loss function for a binary classification task\n",
    "Use an appropriate activation function on the final layer of your network.\n",
    "Train your model using verbose output for ease of grading.\n",
    "Use GridSearchCV or RandomSearchCV to hyperparameter tune your model. (for at least two hyperparameters)\n",
    "When hyperparameter tuning, show you work by adding code cells for each new experiment.\n",
    "Report the accuracy for each combination of hyperparameters as you test them so that we can easily see which resulted in the highest accuracy.\n",
    "You must hyperparameter tune at least 3 parameters in order to get a 3 on this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>257</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "257   50    1   0       144   200    0        0      126      1      0.9   \n",
       "160   56    1   1       120   240    0        1      169      0      0.0   \n",
       "266   55    0   0       180   327    0        2      117      1      3.4   \n",
       "98    43    1   2       130   315    0        1      162      0      1.9   \n",
       "200   44    1   0       110   197    0        0      177      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "257      1   0     3       0  \n",
       "160      0   0     2       1  \n",
       "266      1   0     2       0  \n",
       "98       2   1     2       1  \n",
       "200      2   1     2       0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv')\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xk = df.drop(columns='target')\n",
    "yk = df['target']\n",
    "\n",
    "sc = StandardScaler()\n",
    "Xk = sc.fit_transform(Xk)\n",
    "\n",
    "Xk_train, Xk_test, yk_train, yk_test = train_test_split(Xk, yk, stratify=yk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples\n",
      "Epoch 1/10\n",
      "227/227 [==============================] - 0s 2ms/sample - loss: 0.7945 - accuracy: 0.3348\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 0s 299us/sample - loss: 0.6919 - accuracy: 0.5330\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 0s 293us/sample - loss: 0.6252 - accuracy: 0.6872\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 0s 280us/sample - loss: 0.5669 - accuracy: 0.7797\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 0s 289us/sample - loss: 0.5141 - accuracy: 0.8150\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 0s 311us/sample - loss: 0.4672 - accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 0s 314us/sample - loss: 0.4274 - accuracy: 0.8326\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 0s 282us/sample - loss: 0.3952 - accuracy: 0.8414\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 0s 298us/sample - loss: 0.3725 - accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 0s 296us/sample - loss: 0.3555 - accuracy: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdc6d948e80>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline model with low hyperparams for abtch and epoch\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(20, input_dim=13, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, batch_size=10, epochs=10, verbose=1)\n",
    "model.fit(Xk_train, yk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.814977974618584 using {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.814977974618584, Stdev: 0.044216727600996604 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.7929515373864363, Stdev: 0.0215827404386921 with: {'batch_size': 20, 'epochs': 20}\n",
      "Means: 0.7929515520906658, Stdev: 0.027277156580766918 with: {'batch_size': 50, 'epochs': 20}\n",
      "Means: 0.6343612347930538, Stdev: 0.09539719978617034 with: {'batch_size': 200, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Testing for batch size first\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(20, input_dim=13, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "p = {'batch_size': [10, 20, 50, 200], 'epochs': [20], }\n",
    "              \n",
    "              \n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=p, n_jobs=1)\n",
    "grid_result = grid.fit(Xk_train, yk_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.837004405023768 using {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.8017621260907681, Stdev: 0.03981353037095379 with: {'batch_size': 10, 'epochs': 20}\n",
      "Means: 0.837004405023768, Stdev: 0.022725458980421796 with: {'batch_size': 10, 'epochs': 40}\n",
      "Means: 0.8061674058699922, Stdev: 0.01188552266062769 with: {'batch_size': 10, 'epochs': 60}\n",
      "Means: 0.7797356836071099, Stdev: 0.022077530515565644 with: {'batch_size': 10, 'epochs': 80}\n",
      "Means: 0.8105726953645109, Stdev: 0.016266509406020146 with: {'batch_size': 10, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# 10 batch size was best, now to test for epochs\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(20, input_dim=13, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "p = {'batch_size': [10], 'epochs': [20, 40, 60, 80, 100] }\n",
    "              \n",
    "              \n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=p, n_jobs=1)\n",
    "grid_result = grid.fit(Xk_train, yk_train)\n",
    "\n",
    "# Report Results\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 227 samples\n",
      "Epoch 1/40\n",
      "227/227 [==============================] - 1s 2ms/sample - loss: 0.6684 - accuracy: 0.5639\n",
      "Epoch 2/40\n",
      "227/227 [==============================] - 0s 295us/sample - loss: 0.5904 - accuracy: 0.7225\n",
      "Epoch 3/40\n",
      "227/227 [==============================] - 0s 295us/sample - loss: 0.5271 - accuracy: 0.8018\n",
      "Epoch 4/40\n",
      "227/227 [==============================] - 0s 297us/sample - loss: 0.4763 - accuracy: 0.8150\n",
      "Epoch 5/40\n",
      "227/227 [==============================] - 0s 296us/sample - loss: 0.4381 - accuracy: 0.8370\n",
      "Epoch 6/40\n",
      "227/227 [==============================] - 0s 318us/sample - loss: 0.4092 - accuracy: 0.8370\n",
      "Epoch 7/40\n",
      "227/227 [==============================] - 0s 311us/sample - loss: 0.3863 - accuracy: 0.8370\n",
      "Epoch 8/40\n",
      "227/227 [==============================] - 0s 295us/sample - loss: 0.3710 - accuracy: 0.8326\n",
      "Epoch 9/40\n",
      "227/227 [==============================] - 0s 322us/sample - loss: 0.3587 - accuracy: 0.8370\n",
      "Epoch 10/40\n",
      "227/227 [==============================] - 0s 309us/sample - loss: 0.3489 - accuracy: 0.8458\n",
      "Epoch 11/40\n",
      "227/227 [==============================] - 0s 296us/sample - loss: 0.3403 - accuracy: 0.8414\n",
      "Epoch 12/40\n",
      "227/227 [==============================] - 0s 303us/sample - loss: 0.3344 - accuracy: 0.8458\n",
      "Epoch 13/40\n",
      "227/227 [==============================] - 0s 293us/sample - loss: 0.3263 - accuracy: 0.8414\n",
      "Epoch 14/40\n",
      "227/227 [==============================] - 0s 283us/sample - loss: 0.3215 - accuracy: 0.8458\n",
      "Epoch 15/40\n",
      "227/227 [==============================] - 0s 300us/sample - loss: 0.3148 - accuracy: 0.8458\n",
      "Epoch 16/40\n",
      "227/227 [==============================] - 0s 298us/sample - loss: 0.3103 - accuracy: 0.8502\n",
      "Epoch 17/40\n",
      "227/227 [==============================] - 0s 304us/sample - loss: 0.3032 - accuracy: 0.8590\n",
      "Epoch 18/40\n",
      "227/227 [==============================] - 0s 294us/sample - loss: 0.2990 - accuracy: 0.8634\n",
      "Epoch 19/40\n",
      "227/227 [==============================] - 0s 290us/sample - loss: 0.2961 - accuracy: 0.8634\n",
      "Epoch 20/40\n",
      "227/227 [==============================] - 0s 284us/sample - loss: 0.2894 - accuracy: 0.8678\n",
      "Epoch 21/40\n",
      "227/227 [==============================] - 0s 293us/sample - loss: 0.2858 - accuracy: 0.8678\n",
      "Epoch 22/40\n",
      "227/227 [==============================] - 0s 306us/sample - loss: 0.2811 - accuracy: 0.8722\n",
      "Epoch 23/40\n",
      "227/227 [==============================] - 0s 307us/sample - loss: 0.2749 - accuracy: 0.8767\n",
      "Epoch 24/40\n",
      "227/227 [==============================] - 0s 332us/sample - loss: 0.2702 - accuracy: 0.8767\n",
      "Epoch 25/40\n",
      "227/227 [==============================] - 0s 297us/sample - loss: 0.2661 - accuracy: 0.8767\n",
      "Epoch 26/40\n",
      "227/227 [==============================] - 0s 296us/sample - loss: 0.2624 - accuracy: 0.8767\n",
      "Epoch 27/40\n",
      "227/227 [==============================] - 0s 292us/sample - loss: 0.2576 - accuracy: 0.8811\n",
      "Epoch 28/40\n",
      "227/227 [==============================] - 0s 287us/sample - loss: 0.2539 - accuracy: 0.8899\n",
      "Epoch 29/40\n",
      "227/227 [==============================] - 0s 280us/sample - loss: 0.2500 - accuracy: 0.8943\n",
      "Epoch 30/40\n",
      "227/227 [==============================] - 0s 301us/sample - loss: 0.2461 - accuracy: 0.8943\n",
      "Epoch 31/40\n",
      "227/227 [==============================] - 0s 297us/sample - loss: 0.2424 - accuracy: 0.8943\n",
      "Epoch 32/40\n",
      "227/227 [==============================] - 0s 291us/sample - loss: 0.2374 - accuracy: 0.8943\n",
      "Epoch 33/40\n",
      "227/227 [==============================] - 0s 304us/sample - loss: 0.2339 - accuracy: 0.8943\n",
      "Epoch 34/40\n",
      "227/227 [==============================] - 0s 300us/sample - loss: 0.2312 - accuracy: 0.8943\n",
      "Epoch 35/40\n",
      "227/227 [==============================] - 0s 335us/sample - loss: 0.2291 - accuracy: 0.8943\n",
      "Epoch 36/40\n",
      "227/227 [==============================] - 0s 285us/sample - loss: 0.2237 - accuracy: 0.9075\n",
      "Epoch 37/40\n",
      "227/227 [==============================] - 0s 304us/sample - loss: 0.2196 - accuracy: 0.8987\n",
      "Epoch 38/40\n",
      "227/227 [==============================] - 0s 304us/sample - loss: 0.2159 - accuracy: 0.8987\n",
      "Epoch 39/40\n",
      "227/227 [==============================] - 0s 315us/sample - loss: 0.2130 - accuracy: 0.9119\n",
      "Epoch 40/40\n",
      "227/227 [==============================] - 0s 298us/sample - loss: 0.2107 - accuracy: 0.9031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fda790a7be0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, verbose=1, batch_size=10, epochs=40)\n",
    "model.fit(Xk_train, yk_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### The accuracy went up due to tuning, however more hyperparams need to be added for better performance.\n",
    "### Also the hyperparams best picked from grid search were close to the low params chosen for baseline."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
